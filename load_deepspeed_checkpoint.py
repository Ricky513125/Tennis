"""
ä» DeepSpeed checkpoint ä¸­åŠ è½½æ¨¡å‹æƒé‡
DeepSpeed checkpoint æ ¼å¼ï¼šç›®å½•åŒ…å« checkpoint/mp_rank_00_model_states.pt
"""
import torch
import logging
from pathlib import Path

logger = logging.getLogger(__name__)


def load_deepspeed_checkpoint(ckpt_path):
    """
    ä» DeepSpeed checkpoint ç›®å½•åŠ è½½æ¨¡å‹æƒé‡
    
    Args:
        ckpt_path: DeepSpeed checkpoint ç›®å½•è·¯å¾„ï¼ˆä¾‹å¦‚ï¼šepoch=49-loss=0.6095ï¼‰
                   æˆ– checkpoint æ–‡ä»¶è·¯å¾„ï¼ˆä¾‹å¦‚ï¼šepoch=49-loss=0.6095/checkpoint/mp_rank_00_model_states.ptï¼‰
    
    Returns:
        state_dict: æ¨¡å‹çš„çŠ¶æ€å­—å…¸
    """
    ckpt_path = Path(ckpt_path)
    
    # å¦‚æœæ˜¯ç›®å½•ï¼ŒæŸ¥æ‰¾ checkpoint æ–‡ä»¶
    if ckpt_path.is_dir():
        # å°è¯•æŸ¥æ‰¾ checkpoint å­ç›®å½•
        checkpoint_dir = ckpt_path / "checkpoint"
        if checkpoint_dir.exists():
            model_states_file = checkpoint_dir / "mp_rank_00_model_states.pt"
            if model_states_file.exists():
                logger.info(f"Loading DeepSpeed checkpoint from: {model_states_file}")
                state_dict = torch.load(model_states_file, map_location="cpu")
                
                # DeepSpeed checkpoint æ ¼å¼ï¼š{"module": {...}}
                if "module" in state_dict:
                    return state_dict["module"]
                elif "model" in state_dict:
                    return state_dict["model"]
                else:
                    # ç›´æ¥è¿”å›æ•´ä¸ªå­—å…¸
                    return state_dict
            else:
                raise FileNotFoundError(f"Model states file not found: {model_states_file}")
        else:
            raise FileNotFoundError(f"Checkpoint directory not found: {checkpoint_dir}")
    
    # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œç›´æ¥åŠ è½½
    elif ckpt_path.is_file():
        logger.info(f"Loading checkpoint file from: {ckpt_path}")
        state_dict = torch.load(ckpt_path, map_location="cpu")
        
        if "module" in state_dict:
            return state_dict["module"]
        elif "model" in state_dict:
            return state_dict["model"]
        else:
            return state_dict
    
    else:
        raise FileNotFoundError(f"Checkpoint path does not exist: {ckpt_path}")


def extract_encoder_weights(state_dict, prefix="model."):
    """
    ä»å®Œæ•´çš„çŠ¶æ€å­—å…¸ä¸­æå– encoder æƒé‡
    
    Args:
        state_dict: å®Œæ•´çš„çŠ¶æ€å­—å…¸
        prefix: æƒé‡é”®çš„å‰ç¼€ï¼ˆä¾‹å¦‚ "model." æˆ– "_forward_module.model."ï¼‰
    
    Returns:
        encoder_dict: encoder çš„æƒé‡å­—å…¸
    """
    encoder_dict = {}
    
    for k, v in state_dict.items():
        # æŸ¥æ‰¾ encoder ç›¸å…³çš„æƒé‡
        if "encoder." in k:
            # ç§»é™¤å‰ç¼€
            new_key = k
            if prefix in new_key:
                new_key = new_key.replace(prefix, "")
            if "_forward_module." in new_key:
                new_key = new_key.replace("_forward_module.", "")
            
            # åªä¿ç•™ encoder éƒ¨åˆ†
            if new_key.startswith("encoder."):
                encoder_dict[new_key] = v
    
    return encoder_dict


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python load_deepspeed_checkpoint.py <checkpoint_path>")
        print("Example: python load_deepspeed_checkpoint.py ./output/2026-01-09/15-29-49/pretrain_rgb/checkpoints/epoch=49-loss=0.6095")
        sys.exit(1)
    
    ckpt_path = sys.argv[1]
    
    try:
        state_dict = load_deepspeed_checkpoint(ckpt_path)
        print(f"âœ… Successfully loaded checkpoint from: {ckpt_path}")
        print(f"ğŸ“Š Total keys: {len(state_dict)}")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªé”®ä½œä¸ºç¤ºä¾‹
        print("\nğŸ“‹ Sample keys:")
        for i, key in enumerate(list(state_dict.keys())[:10]):
            print(f"  {i+1}. {key}")
        if len(state_dict) > 10:
            print(f"  ... and {len(state_dict) - 10} more keys")
        
        # æå– encoder æƒé‡
        encoder_dict = extract_encoder_weights(state_dict)
        print(f"\nğŸ”§ Encoder keys: {len(encoder_dict)}")
        
    except Exception as e:
        print(f"âŒ Error loading checkpoint: {e}")
        import traceback
        traceback.print_exc()
